In regards to the dataset chosen.
The dataset used for this exercise was the records of total rainfall over the UK spanning months and years. The data was 
originally split into the year, the twelve months and the total rainfall over that year. The data spanned from 1836 to 2023.
The year was removed from the pool and the total rainfall was replaced by checking if it was within 150 of the average of 
UK rainfall and titled accordingly.

In regards to the use and purpose of the dataset.
Predicting whether the rainfall will be within the average of the year. This can have multiple uses for example catching trends
in which subsiquent years have had repeatedly higher than average rainfall or catching possible droughts early on in the year 
to prepare.

On the topic of [insert reference to research document] (Go find it again because it's starred on home comp)

In regards to exploration of the dataset.
The original analysis of the dataset was completed using Random forest. This, however, only gave an accuracy rating of around
70.18%. There was a possibility that this was simply due to the nature of the dataset itself as weather and therefore rainfalll are
nutoriously hard to predict. However the confusion matrix showed that most incorrect predictions were heavily squewed towards the
average label with heavy rainfall having been the worst effected not containing a single correct prediction. The speculation
for this event was the lack of this result in the training set as it was much more common towards the end of the data set as
opposed to the beginning. With this conclusion in mind the response was to find a method to cluster the data to increase the 
likelyhood that it would be correctly trained to identify the three different types. KMeans was chosen to accomplish this but 
does not function when used with strings and as such the label of ann (annual) was repaced with a numberical representation:
0 for light rainfall, 1 for average rainfall and 2 for heavy rainfall. 
After implementing the use of KMeans to cluster data the accuracy of the model increased to around 87.72%.
, also  try a different method of classification.
double check, use SVM if possible. I think something's gone *WRONG*
